{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Behavioral Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Declare and import dependencies on modules. Also declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"recorded-data\"\n",
    "#data_path = \"data-from-udacity/data\"\n",
    "generator_batch_size = 100\n",
    "steering_offset = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load lines from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_lines(path):\n",
    "    lines = []\n",
    "    with open(path + \"/driving_log.csv\") as datafile:\n",
    "        reader = csv.reader(datafile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract center, left and right images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_images(line):\n",
    "    center_image = cv2.imread(data_path + \"/IMG/\" + line[0].replace(\"\\\\\", \"/\").split(\"/\")[-1])\n",
    "    left_image = cv2.imread(data_path + \"/IMG/\" + line[1].replace(\"\\\\\", \"/\").split(\"/\")[-1])\n",
    "    right_image = cv2.imread(data_path + \"/IMG/\" + line[2].replace(\"\\\\\", \"/\").split(\"/\")[-1])\n",
    "    return (center_image, left_image, right_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract steering angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_steering_angles(line):\n",
    "    steering_angle_center = float(line[3])\n",
    "    steering_angle_left = steering_angle_center + steering_offset\n",
    "    steering_angle_right = steering_angle_center - steering_offset\n",
    "    return (steering_angle_center, steering_angle_left, steering_angle_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data without generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_without_generator(path, lines):\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    for line in lines:\n",
    "        center_image, left_image, right_image = extract_images(line)\n",
    "        steering_angle_center, steering_angle_left, steering_angle_right = extract_steering_angles(line)\n",
    "        images.extend([center_image, left_image, right_image])\n",
    "        steering_angles.extend([steering_angle_center, steering_angle_left, steering_angle_right])\n",
    "    return np.array(images), np.array(steering_angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data with generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_generator(lines, generator_batch_size=100):\n",
    "    offset = 0\n",
    "    shuffled_lines = shuffle(lines)\n",
    "    while 1:\n",
    "        images = []\n",
    "        steering_angles = []\n",
    "        line_batch = shuffled_lines[offset : offset + generator_batch_size]\n",
    "        for line in line_batch:\n",
    "            center_image, left_image, right_image = extract_images(line)\n",
    "            center_image, left_image,right_image = resize(center_image, (0.25, 0.25)), resize(left_image,(0.25, 0.25)), resize(right_image, (0.25, 0.25))\n",
    "            center_image, left_image,right_image = crop_image(center_image), crop_image(left_image), crop_image(right_image)\n",
    "            steering_angle_center, steering_angle_left, steering_angle_right = extract_steering_angles(line)\n",
    "            images.extend([center_image, left_image, right_image])\n",
    "            steering_angles.extend([steering_angle_center, steering_angle_left, steering_angle_right])\n",
    "            \n",
    "            \n",
    "            center_image, left_image,right_image = flip_horizontal(center_image), flip_horizontal(left_image), flip_horizontal(right_image)\n",
    "            steering_angle_center, steering_angle_left, steering_angle_right = (steering_angle_center*-1), (steering_angle_left*-1), (steering_angle_right*-1), \n",
    "            images.extend([center_image, left_image, right_image])\n",
    "            steering_angles.extend([steering_angle_center, steering_angle_left, steering_angle_right])\n",
    "            \n",
    "        offset += generator_batch_size\n",
    "        if (offset >= len(lines)):\n",
    "            offset = 0\n",
    "            shuffled_lines = shuffle(lines)\n",
    "        yield (np.array(images), np.array(steering_angles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop upper portion of image to retain only lane information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_image(image):\n",
    "    mask = np.ones_like(image)\n",
    "    xsize, ysize = image.shape[1], image.shape[0]\n",
    "    vertices = ((0, 0.4375*ysize), (0, ysize), (xsize, ysize), (xsize, 0.4375*ysize))\n",
    "    vertexArr = []\n",
    "    for vertex in vertices:\n",
    "        vertexArr.append((vertex[0], vertex[1]))\n",
    "    vertexArr = np.array([vertexArr], dtype=np.int32)\n",
    "    \n",
    "    cv2.fillPoly(mask, vertexArr, (255, 255, 255))\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image\n",
    "# lines = load_lines(data_path)\n",
    "# maskedImage = crop_image(extract_images(lines[100])[0])\n",
    "# plt.imshow(maskedImage)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-size images to reduce model training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize(image, scale_factor):\n",
    "    resized_image = cv2.resize(image, (0,0), fx=scale_factor[0], fy=scale_factor[1]) \n",
    "    return resized_image\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n",
    "# plt.imshow(resized_image)\n",
    "# plt.show()\n",
    "# lines = load_lines(data_path)\n",
    "# resize(extract_images(lines[100])[0], (0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flip images to increase and generalize the dataset to left and right turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_horizontal(image):\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    return flipped_image\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n",
    "# plt.imshow(flipped_image)\n",
    "# plt.show()\n",
    "# lines = load_lines(data_path)\n",
    "# flip_horizontal(extract_images(lines[100])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Training using custom network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_custom(training_generator, validation_generator, batch_size=50, epochs=10, use_generator=True):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(160, 320, 3)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    #model.fit(training_generator, validation_generator, validation_split=0.3, shuffle=True, nb_epoch=20)\n",
    "    model.fit_generator(training_generator, nb_epoch=epochs, samples_per_epoch=batch_size)\n",
    "    model.save(\"CarND-Behavioral-Cloning-P3/model-custom-network.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Training using LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_lenet(training_generator, validation_generator, nb_training, nb_validation, epochs=10, use_generator=True):\n",
    "    model = Sequential()\n",
    "    #model.add(Convolution2D(6, 5, 5, border_mode='valid', input_shape=(160, 320, 3)))\n",
    "    #model.add(Convolution2D(6, 5, 5, border_mode='valid', input_shape=(80, 160, 3)))\n",
    "    model.add(Convolution2D(6, 5, 5, border_mode='valid', input_shape=(40, 80, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    #model.add(Convolution2D(16, 5, 5, border_mode='valid', input_shape=(156, 316, 6)))\n",
    "    #model.add(Convolution2D(16, 5, 5, border_mode='valid', input_shape=(76, 156, 6)))\n",
    "    #model.add(Convolution2D(16, 5, 5, border_mode='valid', input_shape=(36, 76, 6)))\n",
    "    model.add(Convolution2D(16, 5, 5, border_mode='valid'))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    #model.add(Flatten(input_shape=(152, 312, 16)))\n",
    "    #model.add(Flatten(input_shape=(72, 152, 16)))\n",
    "    #model.add(Flatten(input_shape=(32, 72, 16)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(84))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    if use_generator:\n",
    "        model.fit_generator(training_generator, validation_data=validation_generator, nb_epoch=epochs, samples_per_epoch=(nb_training+nb_validation), nb_val_samples=nb_validation)\n",
    "    else:\n",
    "        model.fit(training_generator[0], training_generator[1], validation_split=0.2, shuffle=True, nb_epoch=epochs)\n",
    "    metrics = model.evaluate_generator(validation_generator, val_samples=nb_validation)\n",
    "    print(metrics)\n",
    "    model.save(\"CarND-Behavioral-Cloning-P3/model-lenet-udacity-data.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10128/10410 [============================>.] - ETA: 0s - loss: 177.0996 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10728/10410 [==============================] - 25s - loss: 167.3108 - val_loss: 5.8167\n",
      "5.58017363535\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-1bcea49c2685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#training_images, steering_angles = get_data_without_generator(data_path, lines)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#train_model_lenet((training_images, steering_angles), None, None, None, epochs=4, use_generator=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-124-1bcea49c2685>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_model_lenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#training_images, steering_angles = get_data_without_generator(data_path, lines)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-9f0d0771d841>\u001b[0m in \u001b[0;36mtrain_model_lenet\u001b[0;34m(training_generator, validation_generator, nb_training, nb_validation, epochs, use_generator)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmetric_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mmetric_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CarND-Behavioral-Cloning-P3/model-lenet-udacity-data.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    lines = load_lines(data_path)[1:]\n",
    "    training_set_lines, validation_set_lines = train_test_split(lines, test_size=0.2)\n",
    "    #training_set_lines = lines[0:50]\n",
    "    #validation_set_lines = lines[50:60]\n",
    "    nb_training = len(training_set_lines)*6\n",
    "    nb_validation = len(validation_set_lines)*6\n",
    "\n",
    "    training_generator = get_data_generator(training_set_lines, generator_batch_size=generator_batch_size)\n",
    "    validation_generator = get_data_generator(validation_set_lines, generator_batch_size=generator_batch_size)\n",
    "    \n",
    "    train_model_lenet(training_generator, validation_generator, nb_training, nb_validation, epochs=1, use_generator=True)\n",
    "\n",
    "    #training_images, steering_angles = get_data_without_generator(data_path, lines)\n",
    "    #train_model_lenet((training_images, steering_angles), None, None, None, epochs=4, use_generator=False)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
