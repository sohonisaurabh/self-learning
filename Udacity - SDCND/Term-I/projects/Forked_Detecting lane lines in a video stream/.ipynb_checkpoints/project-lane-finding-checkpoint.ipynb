{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Cell below contains all import code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readImg(path):\n",
    "    image = mpimg.imread(path)\n",
    "    #Returns the image\n",
    "    return image\n",
    "#plt.imshow(readImg(collectImages(\"test_images\")[0]))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting image names from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collectImages(folderPath):\n",
    "    # Returns array of strings with complete path of a file from current folder.\n",
    "    return [folderPath + imageName for imageName in os.listdir(folderPath + \"/\")]\n",
    "#print (collectImages(\"test_images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert RGB image to Gray Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertToGrayScale (rgbImage):\n",
    "    grayImage = np.copy(rgbImage)\n",
    "    # Returns 8 bit image array converted from input 32-bit (8+8+8) RGB image.\n",
    "    return cv2.cvtColor(grayImage, cv2.COLOR_RGB2GRAY)\n",
    "#plt.imshow(convertToGrayScale(readImg(collectImages(\"test_images\")[0])[0]), cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def applyGaussianBlur (image, kernelSize=3):\n",
    "    filteredImage = np.copy(image)\n",
    "    # Return image array after applying Gaussian blur. Image array size depends on input image.\n",
    "    return cv2.GaussianBlur(filteredImage, (kernelSize, kernelSize), 0)\n",
    "#plt.imshow(convertToGrayScale(readImg(collectImages(\"test_images\")[0])[0]), cmap=\"gray\")\n",
    "#plt.show()\n",
    "#plt.imshow(applyGaussianBlur(convertToGrayScale(readImg(collectImages(\"test_images\")[0])[0]), 15), cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cannyEdgeDetector (grayImage, lowThreshold=1, highThreshold=10):\n",
    "    edges = cv2.Canny(grayImage, lowThreshold, highThreshold)\n",
    "    # Returns 8-bit image array of size same as input gray scale image with boolean True for edges and False for non-edges\n",
    "    return edges\n",
    "#plt.imshow(convertToGrayScale(readImg(collectImages(\"test_images\")[2])[0]), cmap=\"gray\")\n",
    "#plt.show()\n",
    "#plt.imshow(cannyEdgeDetector(applyGaussianBlur(convertToGrayScale(readImg(collectImages(\"test_images\")[2])[0]), 5), 50, 200), cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createPolyFilter (vertices):\n",
    "    vertexArr = []\n",
    "    for vertex in vertices:\n",
    "        vertexArr.append((vertex[0], vertex[1]))\n",
    "    vertexArr = np.array([vertexArr], dtype=np.int32)\n",
    "    # Returns array of vertices as ordered pair tuples with data type as 32bit float\n",
    "    return vertexArr\n",
    "#print (createPolyFilter([(0, 0), (3,2), (400,322)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def applyRegionFilter (image, verticeArray):\n",
    "    mask = np.zeros_like(image)\n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(image.shape) > 2:\n",
    "        channel_count = image.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    \n",
    "    #Create polygon and fill pixels inside polgon with ignore_mask_color\n",
    "    cv2.fillPoly(mask, verticeArray, ignore_mask_color)\n",
    "    maskedImage = cv2.bitwise_and(image, mask)\n",
    "    # Returns image of same size as input image after applying region of interest filter\n",
    "    return maskedImage\n",
    "#plt.imshow(cannyEdgeDetector(applyGaussianBlur(convertToGrayScale(readImg(collectImages(\"test_images\")[2])[0]), 5), 50, 200), cmap=\"gray\")\n",
    "#plt.show()\n",
    "#imagexsize = readImg(collectImages(\"test_images\")[1])[1][1]\n",
    "#imageysize = readImg(collectImages(\"test_images\")[1])[1][0]\n",
    "#plt.imshow(applyRegionFilter(cannyEdgeDetector(applyGaussianBlur(convertToGrayScale(readImg(collectImages(\"test_images\")[2])[0]), 5), 50, 200), \\\n",
    "#                           createPolyFilter([(int(imagexsize/10), imageysize),\\\n",
    "#                            (int(imagexsize/2), int(11*imageysize/20)),\\\n",
    "#                            (int(6*imagexsize/10), int(11*imageysize/20)),\\\n",
    "#                           (int(9*imagexsize/10), imageysize)])),\\\n",
    "#          cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw Hough lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drawHoughLines (image, edgeImage, rho=1, theta=(np.pi/180), threshold=1, minLineLength=2, maxLineGap=5, extrapolateLines=False):\n",
    "    houghLines = cv2.HoughLinesP(edgeImage, rho, theta, threshold, np.array([]), minLineLength, maxLineGap)\n",
    "    \n",
    "    if (extrapolateLines):\n",
    "        houghLines = joinAndExtrapolateLineSegments(image, houghLines)\n",
    "    \n",
    "    return houghLines\n",
    "#image = readImg(collectImages(\"test_images\")[5])\n",
    "#imagexsize = image[1][1]\n",
    "#imageysize = image[1][0]\n",
    "#edgeImage = applyRegionFilter(cannyEdgeDetector(applyGaussianBlur(convertToGrayScale(image[0]), 5), 50, 240), \\\n",
    "#                           createPolyFilter([(int(imagexsize/20), imageysize),\\\n",
    "#                            (int(imagexsize/2), int(12*imageysize/20)),\\\n",
    "#                            (int(6*imagexsize/10), int(12*imageysize/20)),\\\n",
    "#                           (int(18*imagexsize/20), imageysize)]))\n",
    "#plt.imshow(edgeImage, cmap=\"gray\")\n",
    "#plt.show()\n",
    "#plt.imshow(drawHoughLines(image[0], edgeImage, threshold=20, minLineLength=20, maxLineGap=80))\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extrapolate lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def joinAndExtrapolateLineSegments (image, lines):\n",
    "    slopeRangeLeft = [0.3, 0.7]\n",
    "    slopeRangeRight = [-0.5, -0.9]\n",
    "    leftLines = []\n",
    "    rightLines = []\n",
    "    averageLines = []\n",
    "    extrapolatedLine = []\n",
    "    imageysize = image.shape[0]\n",
    "    \n",
    "    #Code for segregating into left and right lines\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope, intercept = np.polyfit([x1, x2], [y1, y2], deg=1)\n",
    "            if (slope > slopeRangeLeft[0] and slope < slopeRangeLeft[1]):\n",
    "                leftLines.append(line)\n",
    "            elif (slope < slopeRangeRight[0] and slope > slopeRangeRight[1]):\n",
    "                rightLines.append(line)\n",
    "    \n",
    "    #Calculate average of vectors for left line and add that line to averageLines. No action in case there was no line detected\n",
    "    if (len(leftLines) > 0):\n",
    "        averageLines.append(np.mean(leftLines, axis=0, dtype=np.int32))\n",
    "    #Calculate average of vectors for Right line and add that line to averageLines. No action in case there was no line detected\n",
    "    if (len(rightLines) > 0):\n",
    "        averageLines.append(np.mean(rightLines, axis=0, dtype=np.int32))\n",
    "\n",
    "    #Extrapolate the lines upto y value range of (imageysize/2, imageysize). Extrapolation is not done in X axis\n",
    "    for line in averageLines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope, intercept = np.polyfit([x1, x2], [y1, y2], deg=1)\n",
    "            line = np.array([int((25*imageysize/40 - intercept)/slope), 25*imageysize/40, int((imageysize - intercept)/slope), imageysize], dtype=np.int32)\n",
    "            extrapolatedLine.append([line])\n",
    "            \n",
    "    return extrapolatedLine\n",
    "#image = readImg(collectImages(\"re-test-failed/\")[10])\n",
    "#imagexsize = image.shape[1]\n",
    "#imageysize = image.shape[0]\n",
    "#edgeImage = applyRegionFilter(cannyEdgeDetector(applyGaussianBlur(convertToGrayScale(image), 5), 50, 240), \\\n",
    "#                           createPolyFilter([(int(imagexsize/20), imageysize),\\\n",
    "#                            (int(imagexsize/2), int(12*imageysize/20)),\\\n",
    "#                            (int(6*imagexsize/10), int(12*imageysize/20)),\\\n",
    "#                           (int(18*imagexsize/20), imageysize)]))\n",
    "#plt.imshow(edgeImage, cmap=\"gray\")\n",
    "#plt.show()\n",
    "#plt.imshow(drawLines(image, drawHoughLines(image, edgeImage, threshold=20, minLineLength=20, maxLineGap=80, extrapolateLines=True),\\\n",
    "#                     semiTransparent=True))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw lines on original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawLines (image, lines, thickness=15, color=(255, 0, 0), semiTransparent=False):\n",
    "    lineImage = np.copy(image)\n",
    "    \n",
    "    if (semiTransparent):\n",
    "        blankImage = np.copy(image)*0\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(blankImage, (x1,y1), (x2,y2), color, thickness)\n",
    "        lineImage = cv2.addWeighted(lineImage, 0.8, blankImage, 1, 0)\n",
    "    else:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(lineImage, (x1,y1), (x2,y2), color, thickness)\n",
    "    # Returns original image with lines detected by Hough and/or Extrapolated\n",
    "    return lineImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Lane Finding algorithm on video clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def laneDetectionInVideo (sourceFilePath, outputFilePath, laneLinesExtrapolated=True):\n",
    "    originalVideoClip = VideoFileClip(sourceFilePath)\n",
    "    laneDetectedClip = originalVideoClip.fl_image(processImage, laneLinesExtrapolated)\n",
    "    %time laneDetectedClip.write_videofile(outputFilePath, audio=False)\n",
    "#laneDetectionInVideo(\"solidWhiteRight.mp4\", \"white-lane-detected.mp4\")\n",
    "#laneDetectionInVideo(\"solidYellowLeft.mp4\", \"yellow-lane-detected.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Process image method, combines all steps into one method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processImage (image, laneLinesExtrapolated=True):\n",
    "    imagexsize = image.shape[1]\n",
    "    imageysize = image.shape[0]\n",
    "    \n",
    "    kernelSize = 5\n",
    "    cannyLowThreshold = 50\n",
    "    cannyHighThreshold = 240\n",
    "    regionPolyVector = createPolyFilter([(int(imagexsize/20), imageysize),\\\n",
    "                            (int(imagexsize/2), int(12*imageysize/20)),\\\n",
    "                            (int(6*imagexsize/10), int(12*imageysize/20)),\\\n",
    "                           (int(19*imagexsize/20), imageysize)])\n",
    "\n",
    "    houghThreshold = 15\n",
    "    houghMinLineLenght = 30\n",
    "    houghMaxLineGap = 80\n",
    "\n",
    "    grayScaledImage = convertToGrayScale(image)\n",
    "    gaussianBlurredImage = applyGaussianBlur(grayScaledImage, kernelSize)\n",
    "    edgeImage = cannyEdgeDetector(gaussianBlurredImage, cannyLowThreshold, cannyHighThreshold)\n",
    "    regionSelectedImage = applyRegionFilter(edgeImage, regionPolyVector)\n",
    "    houghLines = drawHoughLines(image, regionSelectedImage, threshold=houghThreshold,\\\n",
    "                                         minLineLength=houghMinLineLenght, maxLineGap=houghMaxLineGap, \\\n",
    "                                extrapolateLines=laneLinesExtrapolated)\n",
    "    imageWithLaneLines = drawLines(image, houghLines, thickness=15, semiTransparent=True)\n",
    "    \n",
    "    #Uncomment this line of code to plot image with lane detected markers\n",
    "    #plt.imshow(imageWithLaneLines)\n",
    "    #plt.show()\n",
    "\n",
    "    return imageWithLaneLines\n",
    "#image = readImg(collectImages(\"test_images/\")[5])\n",
    "#plt.imshow(process_image(image))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main method to test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main (testFor=\"\", laneLinesExtrapolated=True, optionalChallenge=False):\n",
    "    if (testFor == \"images\"):\n",
    "        pathToImageFolder = \"test_images/\"\n",
    "        for imageName in collectImages(pathToImageFolder):\n",
    "            if (imageName.find(\"output\") == -1):\n",
    "                image = readImg(imageName)\n",
    "                laneDetectedImage = processImage(image, laneLinesExtrapolated)\n",
    "                mpimg.imsave(imageName[0:imageName.rindex(\".\")] + \"_output_lane_detected\" + imageName[imageName.rindex(\".\"):], laneDetectedImage)\n",
    "    elif (testFor == \"videos\"):\n",
    "        laneDetectionInVideo(\"solidWhiteRight.mp4\", \"solidWhiteRightLaneDetected.mp4\")\n",
    "        laneDetectionInVideo(\"solidYellowLeft.mp4\", \"solidYellowLeftLaneDetected.mp4\")\n",
    "        if (optionalChallenge):\n",
    "            laneDetectionInVideo(\"challenge.mp4\", \"challengeLaneDetected.mp4\")\n",
    "    else:\n",
    "        print (\"Please specify the source ('images' or 'videos') to apply lane detection algorithm!!\")\n",
    "    \n",
    "#main(\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases\n",
    "\n",
    "To run Lane-Detection code for images and videos, follow steps given below:\n",
    "    1. Click on 'Cell' from menu bar and select 'Run All' from the drop down.\n",
    "    2. Uncomment cells given below for each test case to Run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test on Images\n",
    "\n",
    "Now you should build your pipeline to work on the images in the directory \"test_images\"  \n",
    "**You should make sure your pipeline works well on these images before you try the videos.**\n",
    "\n",
    "**Uncomment code in below cell to test on images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#main(\"images\", laneLinesExtrapolated=False)\n",
    "#main(\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "We can test our solution on two provided videos:\n",
    "\n",
    "`solidWhiteRight.mp4`\n",
    "\n",
    "`solidYellowLeft.mp4`\n",
    "\n",
    "**Uncomment code in below cell to test on videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#main(\"videos\", laneLinesExtrapolated=False)\n",
    "#main(\"videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Try your lane finding pipeline on the video below.  Does it still work?  Can you figure out a way to make it more robust?  If you're up for the challenge, modify your pipeline so it works with this video and submit it along with the rest of your project!\n",
    "\n",
    "challenge.mp4\n",
    "\n",
    "**Uncomment code in below cell to test on videos along with challenge video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#main(\"videos\", optionalChallenge=False)\n",
    "#main(\"videos\", optionalChallenge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "Congratulations on finding the lane lines!  As the final step in this project, we would like you to share your thoughts on your lane finding pipeline... specifically, how could you imagine making your algorithm better / more robust?  Where will your current algorithm be likely to fail?\n",
    "\n",
    "Please add your thoughts below,  and if you're up for making your pipeline more robust, be sure to scroll down and check out the optional challenge video below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "If you're satisfied with your video outputs it's time to submit!  Submit this ipython notebook for review."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
