{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Finding Project\n",
    "\n",
    "Guidelines on the code submission:\n",
    "1. Code is developed using modular approach. Each stage used in lane detection algorithm is tagged with a function/method.\n",
    "2. In the very end, a main() method is used to run the code.\n",
    "3. To verify operation of code, test cases are added in the bottom part of this workbook. Each cell added against a test case simulates lane detection code for the corresponding test case.\n",
    "4. For testing purpose, user is advised to run all cells by clicking on 'Cell' from menu bar and selecting 'Run All' from the drop down.\n",
    "5. Uncomment cells given below for each test case to Run.\n",
    "6. Reflections and analysis on the code is provided below test case section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Cell below contains all import code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readImg(path):\n",
    "    image = mpimg.imread(path)\n",
    "    #Returns the image\n",
    "    return image\n",
    "#plt.imshow(readImg(collectImages(\"test_images\")[0]))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting image names from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collectImages(folderPath):\n",
    "    # Returns array of strings with complete path of a file from current folder.\n",
    "    return [folderPath + imageName for imageName in os.listdir(folderPath + \"/\")]\n",
    "#print (collectImages(\"test_images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert RGB image to Gray Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertToGrayScale (rgbImage):\n",
    "    grayImage = np.copy(rgbImage)\n",
    "    mergedImage = cv2.cvtColor(grayImage, cv2.COLOR_RGB2GRAY)\n",
    "    hsvImage = cv2.cvtColor(grayImage, cv2.COLOR_RGB2HSV)\n",
    "    #Merges HSV image with RGB image\n",
    "    mergedImage = cv2.addWeighted(grayImage, 0.8, hsvImage, 1, 0)\n",
    "    mergedImage = cv2.cvtColor(mergedImage, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Returns 8 bit image array converted from input 32-bit (8+8+8) RGB image.\n",
    "    return mergedImage\n",
    "#plt.imshow(convertToGrayScale(readImg(collectImages(\"test_images/\")[0])), cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def applyGaussianBlur (image, kernelSize=3):\n",
    "    filteredImage = np.copy(image)\n",
    "    # Return image array after applying Gaussian blur. Image array size depends on input image.\n",
    "    return cv2.GaussianBlur(filteredImage, (kernelSize, kernelSize), 0)\n",
    "#plt.imshow(convertToGrayScale(readImg(collectImages(\"challenge-future-scope/\")[0])), cmap=\"gray\")\n",
    "#plt.show()\n",
    "#plt.imshow(applyGaussianBlur(convertToGrayScale(readImg(collectImages(\"challenge-future-scope/\")[0])), 5), cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cannyEdgeDetector (grayImage, lowThreshold=1, highThreshold=10):\n",
    "    edges = cv2.Canny(grayImage, lowThreshold, highThreshold)\n",
    "    # Returns 8-bit image array of size same as input gray scale image with boolean True for edges and False for non-edges\n",
    "    return edges\n",
    "#plt.imshow(convertToGrayScale(readImg(collectImages(\"challenge-future-scope/\")[0])), cmap=\"gray\")\n",
    "#plt.show()\n",
    "#plt.imshow(cannyEdgeDetector(applyGaussianBlur(convertToGrayScale(readImg(collectImages(\"challenge-future-scope/\")[0])), 5), 50, 240), cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createPolyFilter (vertices):\n",
    "    vertexArr = []\n",
    "    for vertex in vertices:\n",
    "        vertexArr.append((vertex[0], vertex[1]))\n",
    "    vertexArr = np.array([vertexArr], dtype=np.int32)\n",
    "    # Returns array of vertices as ordered pair tuples with data type as 32bit float\n",
    "    return vertexArr\n",
    "#print (createPolyFilter([(0, 0), (3,2), (400,322)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def applyRegionFilter (image, verticeArray):\n",
    "    mask = np.zeros_like(image)\n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(image.shape) > 2:\n",
    "        channel_count = image.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    \n",
    "    #Create polygon and fill pixels inside polgon with ignore_mask_color\n",
    "    cv2.fillPoly(mask, verticeArray, ignore_mask_color)\n",
    "    maskedImage = cv2.bitwise_and(image, mask)\n",
    "    # Returns image of same size as input image after applying region of interest filter\n",
    "    return maskedImage\n",
    "#plt.imshow(cannyEdgeDetector(applyGaussianBlur(convertToGrayScale(readImg(collectImages(\"challenge-future-scope/\")[0])), 5), 175, 100), cmap=\"gray\")\n",
    "#plt.show()\n",
    "#imagexsize = readImg(collectImages(\"challenge-future-scope/\")[0]).shape[1]\n",
    "#imageysize = readImg(collectImages(\"challenge-future-scope/\")[0]).shape[0]\n",
    "#plt.imshow(applyRegionFilter(cannyEdgeDetector(applyGaussianBlur(convertToGrayScale(readImg(collectImages(\"challenge-future-scope/\")[0])), 5), 175, 100), \\\n",
    "#                           createPolyFilter([(int(imagexsize/20), imageysize),\\\n",
    "#                            (int(imagexsize/2), int(12*imageysize/20)),\\\n",
    "#                            (int(6*imagexsize/10), int(12*imageysize/20)),\\\n",
    "#                           (int(19*imagexsize/20), imageysize)])),\\\n",
    "#          cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw Hough lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drawHoughLines (image, edgeImage, rho=1, theta=(np.pi/180), threshold=1, minLineLength=2, maxLineGap=5, extrapolateLines=False):\n",
    "    houghLines = cv2.HoughLinesP(edgeImage, rho, theta, threshold, np.array([]), minLineLength, maxLineGap)\n",
    "    \n",
    "    if (extrapolateLines):\n",
    "        houghLines = joinAndExtrapolateLineSegments(image, houghLines)\n",
    "    \n",
    "    return houghLines\n",
    "#image = readImg(collectImages(\"challenge-future-scope/\")[0])\n",
    "#imagexsize = image.shape[1]\n",
    "#imageysize = image.shape[0]\n",
    "#edgeImage = applyRegionFilter(cannyEdgeDetector(applyGaussianBlur(convertToGrayScale(image), 5), 50, 240), \\\n",
    "#                           createPolyFilter([(int(imagexsize/20), imageysize),\\\n",
    "#                            (int(imagexsize/2), int(12*imageysize/20)),\\\n",
    "#                            (int(6*imagexsize/10), int(12*imageysize/20)),\\\n",
    "#                           (int(18*imagexsize/20), imageysize)]))\n",
    "#plt.imshow(edgeImage, cmap=\"gray\")\n",
    "#plt.show()\n",
    "#plt.imshow(drawLines(image, drawHoughLines(image, edgeImage, threshold=20, minLineLength=40, maxLineGap=80, extrapolateLines=True),\\\n",
    "#                     semiTransparent=True))\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extrapolate lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def joinAndExtrapolateLineSegments (image, lines):\n",
    "    slopeRangeLeft = [0.3, 0.7]\n",
    "    slopeRangeRight = [-0.5, -0.9]\n",
    "    leftLines = []\n",
    "    rightLines = []\n",
    "    averageLines = []\n",
    "    extrapolatedLine = []\n",
    "    imageysize = image.shape[0]\n",
    "    \n",
    "    #Code for segregating into left and right lines\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope, intercept = np.polyfit([x1, x2], [y1, y2], deg=1)\n",
    "            if (slope > slopeRangeLeft[0] and slope < slopeRangeLeft[1]):\n",
    "                leftLines.append(line)\n",
    "            elif (slope < slopeRangeRight[0] and slope > slopeRangeRight[1]):\n",
    "                rightLines.append(line)\n",
    "\n",
    "    #Calculate average of vectors for left line and add that line to averageLines. No action in case there was no line detected\n",
    "    if (len(leftLines) > 0):\n",
    "        averageLines.append(np.mean(leftLines, axis=0, dtype=np.int32))\n",
    "    #Calculate average of vectors for Right line and add that line to averageLines. No action in case there was no line detected\n",
    "    if (len(rightLines) > 0):\n",
    "        averageLines.append(np.mean(rightLines, axis=0, dtype=np.int32))\n",
    "\n",
    "    #Extrapolate the lines upto y value range of (imageysize/2, imageysize). Extrapolation is not done in X axis\n",
    "    for line in averageLines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope, intercept = np.polyfit([x1, x2], [y1, y2], deg=1)\n",
    "            #line = np.array([int((25*imageysize/40 - intercept)/slope), 25*imageysize/40, int((imageysize - intercept)/slope), imageysize], dtype=np.int32)\n",
    "            line = np.array([int((25*imageysize/40 - intercept)/slope), 25*imageysize/40, int((imageysize - intercept)/slope), imageysize], dtype=np.int32)\n",
    "            extrapolatedLine.append([line])\n",
    "            \n",
    "    return extrapolatedLine\n",
    "#image = readImg(collectImages(\"test_images/\")[0])\n",
    "#imagexsize = image.shape[1]\n",
    "#imageysize = image.shape[0]\n",
    "#edgeImage = applyRegionFilter(cannyEdgeDetector(applyGaussianBlur(convertToGrayScale(image), 5), 50, 200), \\\n",
    "#                           createPolyFilter([(int(imagexsize/20), 4*imageysize/5),\\\n",
    "#                            (int(imagexsize/2), int(12*imageysize/20)),\\\n",
    "#                            (int(6*imagexsize/10), int(12*imageysize/20)),\\\n",
    "#                           (int(18*imagexsize/20), imageysize)]))\n",
    "#plt.imshow(edgeImage, cmap=\"gray\")\n",
    "#plt.show()\n",
    "#plt.imshow(drawLines(image, drawHoughLines(image, edgeImage, threshold=20, minLineLength=20, maxLineGap=80, extrapolateLines=False),\\\n",
    "#                     semiTransparent=True))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw lines on original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawLines (image, lines, thickness=15, color=(255, 0, 0), semiTransparent=False):\n",
    "    lineImage = np.copy(image)\n",
    "    \n",
    "    if (semiTransparent):\n",
    "        blankImage = np.copy(image)*0\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(blankImage, (x1,y1), (x2,y2), color, thickness)\n",
    "        lineImage = cv2.addWeighted(lineImage, 0.8, blankImage, 1, 0)\n",
    "    else:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(lineImage, (x1,y1), (x2,y2), color, thickness)\n",
    "    # Returns original image with lines detected by Hough and/or Extrapolated\n",
    "    return lineImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Lane Finding algorithm on video clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def laneDetectionInVideo (sourceFilePath, outputFilePath):\n",
    "    originalVideoClip = VideoFileClip(sourceFilePath)\n",
    "    laneDetectedClip = originalVideoClip.fl_image(processImage)\n",
    "    %time laneDetectedClip.write_videofile(outputFilePath, audio=False)\n",
    "#laneDetectionInVideo(\"challenge.mp4\", \"final-challenge-lane-detected.mp4\")\n",
    "#laneDetectionInVideo(\"solidYellowLeft.mp4\", \"final-yellow-lane-detected.mp4\")\n",
    "#laneDetectionInVideo(\"solidWhiteRight.mp4\", \"final-white-lane-detected-plain.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Process image method, combines all steps into one method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processImage (image, laneLinesExtrapolated=True):\n",
    "    imagexsize = image.shape[1]\n",
    "    imageysize = image.shape[0]\n",
    "    \n",
    "    kernelSize = 5\n",
    "    cannyLowThreshold = 50\n",
    "    cannyHighThreshold = 200\n",
    "    regionPolyVector = createPolyFilter([(int(imagexsize/20), imageysize),\\\n",
    "                            (int(imagexsize/2), int(12*imageysize/20)),\\\n",
    "                            (int(6*imagexsize/10), int(12*imageysize/20)),\\\n",
    "                           (int(19*imagexsize/20), imageysize)])\n",
    "\n",
    "    houghThreshold = 20\n",
    "    houghMinLineLenght = 40\n",
    "    houghMaxLineGap = 80\n",
    "\n",
    "    grayScaledImage = convertToGrayScale(image)\n",
    "    gaussianBlurredImage = applyGaussianBlur(grayScaledImage, kernelSize)\n",
    "    edgeImage = cannyEdgeDetector(gaussianBlurredImage, cannyLowThreshold, cannyHighThreshold)\n",
    "    regionSelectedImage = applyRegionFilter(edgeImage, regionPolyVector)\n",
    "    houghLines = drawHoughLines(image, regionSelectedImage, threshold=houghThreshold,\\\n",
    "                                         minLineLength=houghMinLineLenght, maxLineGap=houghMaxLineGap, \\\n",
    "                                extrapolateLines=laneLinesExtrapolated)\n",
    "    imageWithLaneLines = drawLines(image, houghLines, thickness=10, semiTransparent=True)\n",
    "    \n",
    "    #Uncomment this line of code to plot image with lane detected markers\n",
    "    #plt.imshow(imageWithLaneLines)\n",
    "    #plt.show()\n",
    "\n",
    "    return imageWithLaneLines\n",
    "#image = readImg(collectImages(\"test_images/\")[5])\n",
    "#plt.imshow(process_image(image))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main method to test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main (testFor=\"\", laneLinesExtrapolated=True, optionalChallenge=False):\n",
    "    if (testFor == \"images\"):\n",
    "        pathToImageFolder = \"test_images/\"\n",
    "        for imageName in collectImages(pathToImageFolder):\n",
    "            if (imageName.find(\"output\") == -1):\n",
    "                image = readImg(imageName)\n",
    "                laneDetectedImage = processImage(image, laneLinesExtrapolated)\n",
    "                mpimg.imsave(imageName[0:imageName.rindex(\".\")] + \"_output_lane_detected\" + imageName[imageName.rindex(\".\"):], laneDetectedImage)\n",
    "    elif (testFor == \"videos\"):\n",
    "        laneDetectionInVideo(\"solidWhiteRight.mp4\", \"solidWhiteRightLaneDetected.mp4\")\n",
    "        laneDetectionInVideo(\"solidYellowLeft.mp4\", \"solidYellowLeftLaneDetected.mp4\")\n",
    "        if (optionalChallenge):\n",
    "            laneDetectionInVideo(\"challenge.mp4\", \"challengeLaneDetected.mp4\")\n",
    "    else:\n",
    "        print (\"Please specify the source ('images' or 'videos') to apply lane detection algorithm!!\")\n",
    "    \n",
    "#main(\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases\n",
    "\n",
    "To run Lane-Detection code for images and videos, follow steps given below:\n",
    "    1. Click on 'Cell' from menu bar and select 'Run All' from the drop down.\n",
    "    2. Uncomment cells given below for each test case to Run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test on Images\n",
    "\n",
    "Now you should build your pipeline to work on the images in the directory \"test_images\"  \n",
    "**You should make sure your pipeline works well on these images before you try the videos.**\n",
    "\n",
    "**Uncomment code in below cell to test on images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#main(\"images\", laneLinesExtrapolated=False)\n",
    "#main(\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "We can test our solution on two provided videos:\n",
    "\n",
    "`solidWhiteRight.mp4`\n",
    "\n",
    "`solidYellowLeft.mp4`\n",
    "\n",
    "**Uncomment code in below cell to test on videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#main(\"videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Try your lane finding pipeline on the video below.  Does it still work?  Can you figure out a way to make it more robust?  If you're up for the challenge, modify your pipeline so it works with this video and submit it along with the rest of your project!\n",
    "\n",
    "challenge.mp4\n",
    "\n",
    "**Uncomment code in below cell to test on videos along with challenge video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#main(\"videos\", optionalChallenge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "Congratulations on finding the lane lines!  As the final step in this project, we would like you to share your thoughts on your lane finding pipeline... specifically, how could you imagine making your algorithm better / more robust?  Where will your current algorithm be likely to fail?\n",
    "\n",
    "Please add your thoughts below,  and if you're up for making your pipeline more robust, be sure to scroll down and check out the optional challenge video below!\n",
    "\n",
    "**Lane finding algorithm fails in case following scenarios:**\n",
    "1. Gray scale input to Canny edge detector fails where yellow colored lane lines are present and a glare of sunlight is seen on the road. This is because gray pixel mapping for version of yellow color is 226. Also, brighter portions of image map to gray scale value near 200. Hence, canny edge algorithm can't detect edges for yellow lanes.\n",
    "\n",
    "2. When there is shadow casted onto the road. Shadow can be generated by tall buildings, trees, cars on other lanes, etc. Due to moving objects, shadow also moves and hence gets detected as foreground detail in an image.\n",
    "\n",
    "\n",
    "**Algorithm can be made robust by:**\n",
    "1. Merging Gray scale version and **HSV** version of original image and then supplying it to Canny Edge detector after smoothing. Yellow lanes will be more prominent in HSV image as yellow is warm color.\n",
    "\n",
    "2. Removing shadow from images is the next big task. Shadows casting cannot be predicted and is seen a lot in city roads due to presence of high rise buildings. Background subtraction, shadow removal and pixel re-generation algorithms need to be used together to effectively remove shadows. Even in case of shadow, the illumination of region under shadow is similar to its surrounding area. This factor can also be taken into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "If you're satisfied with your video outputs it's time to submit!  Submit this ipython notebook for review."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
